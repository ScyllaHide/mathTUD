\section{(Un)abhängigkeit} \label{sec: unabhaengigkeit}
In vielen Fällen besagt die Intuition über verschiedene Zufallsexperimente / Ereignisse, dass diese sich \textit{nicht} gegenseitig beeinflussen. Für solche $A,B \in \F$ mit $\P(A) > 0$ und $\P(B) > 0$ sollte gelten
\begin{equation*}
	\P(A\mid B) = \P(A) \quad \und \quad \P(B\mid A) = \P(B).
\end{equation*}

\begin{definition} \label{def: 3_2_11}
	Sei $(\Omega, \F, \P)$ Wahrscheinlichkeitsraum. Zwei Ereignisse $A,B \in \F$ heißt \begriff{(stochastisch) unabhängig} bezüglich $\P$, falls
	\begin{equation*}
		\P(A\cap B) = \P(A) * \P(B)
	\end{equation*}
	Wir schreiben auch $A \upmodels B$.
\end{definition}

\begin{beispiel}
	Wir betrachten wieder das Würfeln mit 2 fairen, sechsseitigen Würfeln. 
	\begin{equation*}
		\Omega = \menge{(i,j) \mid i,j \in\menge{1,\dots,n}} \qquad 
		\F = \pows\Omega \qquad 
		\P = \Uni(\Omega)
	\end{equation*}
	Betrachte
	\begin{equation*}
	\begin{aligned}
		A &\defeq \menge{(i,j) \in \Omega \colon i \text{ gerade}}\\
		B &\defeq \menge{(i,j) \in \Omega \colon j \leq 2}
	\end{aligned}
	\end{equation*}
	In diesem Fall, erwarten wir intuitiv die Unabhängigkeit von $A$ und $B$.
	In der Tat ist $\P(A) = \lfrac{1}{2}$, $\P(B) = \lfrac{1}{3}$ und $\P(A\cap B) = \lfrac{1}{6}$, womit $\P(A \cap B) = \P(A) * \P(B)$ erfüllt ist.
	Betrachte nun
	\begin{equation*}
	\begin{aligned}
		C &\defeq \menge{(i,j) \in \Omega \colon i + j = 7}\\
		D &\defeq \menge{(i,j) \in \Omega \colon i = 6}
	\end{aligned}
	\end{equation*}
	Dann gilt $\P(C) = \lfrac{1}{6}$ und $\P(D) = \lfrac{1}{6}$. Wegen $C \cap D = \menge{(6,1)}$ folgt
	\begin{equation*}
		\P(C\cap D) = \frac{1}{36} = \frac{1}{6} * \frac{1}{6} = \P(C) * \P(D)
	\end{equation*}
	$C$ und $D$ sind also \textit{stochastisch} unabhängig, obwohl eine kausale Abhängigkeit vorliegt.
\end{beispiel}

\begin{definition}
	Sei $(\Omega, \F, \P)$ ein Wahrscheinlichkeitsraum und $I \neq \emptyset$ eine endliche Indexmenge. Dann heißt die Familie $(A_i)_{i \in I}$ von Ereignissen in $\F$ \begriff{unabhängig} bezüglich $\P$, falls für alle $\emptyset \neq J \subseteq I$ gilt
	\begin{equation*}
		\P\brackets{\bigcap_{i \in J} A_i} = \prod_{i \in J} \P(A_i)
	\end{equation*}
	Offensichtlich impliziert die Unabhängigkeit einer Familie die paarweise Unabhängigkeit je zweier Familienmitglieder nach \cref{def: 3_2_11}. Umgekehrt gilt dies nicht.
\end{definition}

\begin{beispiel}[Abhängigkeit trotz paarweiser Unabhängigkeit]
	Wir betrachten ein zweifaches Bernoulliexperiment mit Erfolgswahrscheinlichkeit $\lfrac{1}{2}$, d.h.
	\begin{equation*}
		\Omega = \menge{0,1}^2 \qquad \F = \pows\Omega \qquad \P = \Uni(\Omega)
	\end{equation*}
	sowie
	\begin{equation*}
	\begin{aligned}
		A &= \menge{1} \times \menge{0,1} \qquad &&\text{(Münzwurf: erster Wurf ist Zahl)}\\
		B &= \menge{0,1} \times \menge{1} &&\text{(Münzwurf: zweiter Wurf ist Zahl)}\\
		C &= \menge{(0,0), (1,1)} &&\text{(beide Würfe haben selbes Ergebnis)}
	\end{aligned}
	\end{equation*}
	Dann gelten $\P(A) = \lfrac{1}{2} = \P(B) = \P(C)$ und
	\begin{equation*}
	\begin{aligned}
		\P(A\cap B) &= \P(\menge{(1,1)}) = \lfrac{1}{4} = \P(A) * \P(B)\\
		\P(A\cap C) &= \P(\menge{(1,1)}) = \lfrac{1}{4} = \P(A) * \P(C)\\
		\P(B\cap C) &= \P(\menge{(1,1)}) = \lfrac{1}{4} = \P(B) * \P(C)
	\end{aligned}
	\end{equation*}
	Daraus folgt also paarweise Unabhängigkeit. Jedoch ist
	\begin{equation*}
		\P(A \cap B \cap C) = \P(\menge{(1,1)}) = \frac{1}{4} \neq \P(A) * \P(B) * \P(C)
	\end{equation*}
	und $A,B,C$ sind \textit{nicht} stochastisch unabhängig.
\end{beispiel}

\begin{definition}[Unabhängige $\sigma$-Algebren] \label{def: 3_2_15}
	Seien $(\Omega, \F,\P)$ ein Wahrscheinlichkeitsraum, $I \neq \emptyset$ eine Indexmenge und $(E_i, \E_i)$ Messräume.
	\begin{enumerate}[leftmargin=*]
		\item Die Familie $\F_i \subset \F (i \in I)$, heißen \begriff{unabhängig}, wenn für die $\emptyset \neq J \subseteq I$ mit $\abs{J} < \infty$ gilt
		\begin{equation*}
			\P\brackets{\bigcap_{i \in J} A_i} = \prod_{i \in J} \P(A_i) \qquad \text{ für beliebige } A_i \in \F_i (i \in J)
		\end{equation*}
		\item Die Zufallsvariable $\abb{X_i}{(\Omega, \F)}{(E_i, \E_i)} (i \in I)$, heißen \begriff{unabhängig}, wenn die $\sigma$-Algebren
		\begin{equation*}
			\sigma(X_i) = X^{-1}(\E_i) = \menge{\menge{X_i \in F} \colon F \in \E_i} \quad (i \in I)
		\end{equation*}
		unabhängig sind.
	\end{enumerate}
\end{definition}
%
%\begin{lemma}[Zusammenhang der Definitionen]
%	\proplbl{3_2_16}
%	Sei $(\Omega,\F,\P)$ Wahrscheinlichkeitsraum, $I \neq \emptyset, A \in \F, i \in I$. 
%	Die folgenden Aussagen sind äquivalent:
%	\begin{enumerate}
%		\item Die Ereignisse $A_i, i \in I$ sind unabhängig. 
%		\item Die $\sigma$-Algebren $\sigma(A_i), i \in I$ sind unabhängig.
%		\item Die Zufallsvariablen $\indi_{A_i}, i \in I$ sind unabhängig.
%	\end{enumerate}
%\end{lemma}
%\begin{proof} %TODO add ref?
%	Da die Unabhängigkeit über endliche Teilemengen definiert ist, können wir oBdA $I = \menge{1, \dots, n}$ annehmen. 
%	\begin{itemize}
%		\item Da $\sigma(\indi_{A_i}) = \sigma(A_i)$ folgt die Äquivalenz von 2. und 3. direkt aus \propref{3_2_15}.
%		\item Zudem ist 2. $\to$ 1. klar!
%		\item Für 1 $\to$ 2. genügt es zu zeigen, dass
%		\begin{align*}
%			A_1, \dots, A_n \text{ unabhängig } &\Rightarrow B_1, \dots, B_n \text{ unabhängig mit } B_i \in \menge{\emptyset, A_i, A_i^C, \Omega}.
%			\intertext{Rekursiv folgt dies bereits aus}
%			A_1,\dots, A_n \text{ unabhängig } &\Rightarrow B_1, A_2, \dots, A_n \text{ unabhängig mit } B_1 \in \menge{\emptyset, A_1, A_1^C, \Omega}.
%		\end{align*}
%		Für $B_1 \in \menge{\emptyset, A_1, \Omega}$ ist dies klar.\\
%		Sei also $B_1 = A_1^C$ und $J \subseteq I, J \neq \emptyset$. Falls $1 \not \in J$, ist nichts zu zeigen. Sei $1 \in J$, dann gilt mit
%		\begin{align*}
%			A &= \bigcap_{i\in J, i \neq 1} A_i
%			\intertext{sicherlich}
%			\P\brackets{A_1^C \cap A} &= \P(A \mengeminus (A_1 \cap A))\\
%			&= \P(A) - \P(A_1 \cap A)\\
%			&= \prod_{i\in J\mengeminus \menge{1}} \P(A_i) - \prod_{i\in J}(A_i)\\
%			&= (1- \P(A_1))\prod_{i\in J\mengeminus \menge{1}} \P(A_i)\\
%			&= \P\brackets{A_1^C})\prod_{i\in J\mengeminus \menge{1}} \P(A_i)
%		\end{align*} 
%	\end{itemize}
%\end{proof}
%
%Insbesondere zeigt \propref{3_2_16}, dass wir in einer Familie unabhängiger Ereignisse beliebig viele Ereignisse durch ihr Komplement, $\emptyset$ oder $\Omega$ ersetzen können, ohne die Unabhängigkeit zu verlieren.
%
%\begin{proposition}
%	\proplbl{3_2_17}
%	Sei $(\Omega, \F, \P)$ Wahrscheinlichkeitsraum und $\F_i \subseteq \F, i \in I$, seien $\cap$-stabile Familien von Ereignissen. Dann gilt
%	\begin{align*}
%	\F_i, i \in I \text{ unabhängig } \Leftrightarrow \sigma(\F_i), i \in I \text{ unabhängig}. 
%	\end{align*}
%\end{proposition}
%
%\begin{proof}
%	oBdA sei $I = \menge{1, \dots, n}$ und $\Omega \in \F_i, i \in I$.
%	\begin{itemize}
%		\item $\Leftarrow$: trivial, da $\F_i \subseteq \sigma(\F_i)$ und das Weglassen von Mengen erlaubt ist.
%		\item $\Rightarrow$: zeigen wir rekursiv
%		\begin{enumerate}
%			\item Wähle $F_i \in \F_i, i = 2, \dots,n$ und defniere für $F \in \sigma(\F_i)$ die endlichen Maße
%			\begin{align*}
%				\mu(F) = \P\brackets{ F \cap F_2 \cap \cdots \cap F_n} \und \nu(F) = \P(F) \, \P(F_2) \, \dots \, \P(F_n)
%			\end{align*}
%			\item Da die Familien $\F_i$ unabhängig sind, gilt
%			$\mu\mid_{\F_1} = \nu\mid_{\F_1}$.
%			Nach dem Eindeutigkeitssatz für Maße (\proplbl{1_1_19}) folgt $\mu\mid_{\sigma(\F_1)} = \nu\mid_{\sigma(\F_1)}$ also
%			\begin{align*}
%				\P\brackets{ F \cap F_2 \cap \cdots \cap F_n} = \P(F) \P(F_2) \dots \P(F_n)
%			\end{align*}
%			für alle $F \in \sigma(\F_i)$ und $F_i \in \F_i, i = 1, \dots, n$. Da $\Omega \in \F_i$ für alle $i$ gilt die erhaltene Produktformel auf für alle Teilemengen $J \subseteq I$.\\
%			Also sind
%			\begin{align*}
%			\sigma(\F_1), \F_2, \dots, \F_n \text{unabhängig}
%			\end{align*}
%			\item Wiederholtes Anwenden von $1$ und $2$ liefert den Satz.
%		\end{enumerate}
%	\end{itemize}
%\end{proof}
%
%Mit \propref{3_2_17} folgen:
%
%\begin{conclusion}
%	Sei $(\Omega,\F,\P)$ Wahrscheinlichkeitsraum und
%	\begin{align*}
%		\F_{i,j} \subseteq \F, \quad 1 \le i \le n, 1 \le j \le m(i)
%	\end{align*}
%	unabhängige, $\cap$-stabile Familien.
%	Dann sind auch
%	\begin{align*}
%		\G_i = \sigma(\F_{i,1}, \dots , \F_{i,m(i)}), \quad 1 \le i \le n
%	\end{align*}
%	unabhängig.
%\end{conclusion}
%
%\begin{conclusion}
%	Sei $(\Omega,\F,\P)$ Wahrscheinlichkeitsraum und
%	\begin{align*}
%		X_{ij}: \Omega \to E, \quad 1 \le i \le n, 1 \le j \le m(i)
%	\end{align*}
%	unabhängige Zufallsvariablen. Zudem seinen $f_i: E^{m(i)} \to \R$ messbar. Dann sind auch die Zufallsvariablen
%	\begin{align*}
%		f_i(X_{i,1}, \dots, X_{i,m(i)}), \quad 1 \le i \le n
%	\end{align*}
%	unabhängig.
%\end{conclusion}
%
%\begin{example}
%	$X_1, \dots, X_n$ unabhängige reelle Zufallsvariablen. Dann sind auch
%	\begin{align*}
%	Y_1 = X_1, Y_2 = X_2 + \cdots + X_n
%	\end{align*}
%	unabhängig.
%\end{example}